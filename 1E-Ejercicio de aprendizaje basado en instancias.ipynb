{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aprendizaje basado en instancias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Procesado de los datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El conjunto de datos sobre c√°ncer de mama est√° incluido en *Scikit-learn*, se obtiene usando la funci√≥n `load_breast_cancer` incluida en la librer√≠a `sklearn.datasets`. Este conjunto de datos contiene 569 ejemplos con 30 caracter√≠sticas sobre clasificaciones de c√°ncer de mama, con dos clasificaciones posibles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "\n",
    "cancer = load_breast_cancer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este conjunto de datos es un diccionario con varios campos:\n",
    "* `data`: Es el conjunto de datos, se trata de un array en el que cada componente es un array con las caracter√≠sticas de cada instancia.\n",
    "* `target`: Es el conjunto de valores de clasificaci√≥n para cada instancia. Es un array del mismo tama√±o que `data`, en el que se indica el valor de clasificaci√≥n de cada instancia, en el mismo orden en que √©stas se encuentran en el array `data`.\n",
    "* `DESCR`: Es una descripci√≥n del conjunto de datos.\n",
    "* `target_names`: Es un array con los nombres de cada valor de clasificaci√≥n.\n",
    "* `feature_names`: Es un array con los nombres de cada caracter√≠stica.\n",
    "\n",
    "Almacenamos los datos en las variables `X_data`, `y_data`, `X_names` e `y_names`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_data, y_data, X_names, y_names = \\\n",
    "    cancer.data, cancer.target, cancer.feature_names, cancer.target_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejemplos aislados (*outliers*)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Un ejemplo aislado (*outlier* en ingl√©s) es un ejemplo de entrenamiento que est√° rodeado por ejemplos que no pertenecen a su misma clase. La presencia de ejemplos aislados en un conjunto de entrenamiento puede deberse a:\n",
    "\n",
    "* Un error en los datos\n",
    "* Una cantidad insuficiente de ejemplos de la clase de los ejemplos aislados\n",
    "* La existencia de caracter√≠sticas que no se est√°n teniendo en cuenta\n",
    "* Clases desbalanceadas \n",
    "\n",
    "En el contexto de la clasificaci√≥n basada en instancias mediante el algoritmo **k**-*NN*, los ejemplos aislados generan ruido que disminuye el rendimiento del clasificador. Dados dos n√∫meros naturales, $k$ y $r$, con $k>r$, decimos que un ejemplo es ($k$,$r$)-aislado si en sus $k$ vecinos m√°s cercanos hay m√°s de $r$ ejemplos que no pertenecen a su misma clase."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este ejercicio vamos a identificar ejemplos ($k$,$r$)-aislados en el conjunto de datos y vamos a comparar el rendimiento del clasificador **K**-*NN* con y sin estos ejemplos. Para ello vamos a utilizar la clase `NearestNeighbors` de *Scikit-learn*, incluida en la librer√≠a `sklearn.neighbors`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import NearestNeighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contenido del ejercicio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El ejercicio consiste en\n",
    "\n",
    "* Investigar la clase `NearestNeighbors` de *Scikit-learn* y c√≥mo se usa para obtener los vecinos m√°s cercanos a un ejemplo dado dentro de un conjunto de datos, con respecto a una medida de distancia.\n",
    "* Definir la funci√≥n `buscaOutliers` que dados dos n√∫meros naturales `k` y `r`, devuelve la lista de los √≠ndices de los ejemplos del conjunto de entrenamiento sobre el c√°ncer que son (`k`,`r`)-aislados. Es decir, la lista de los √≠ndices de los ejemplos del conjunto de entrenamiento `X_data` para los que en sus `k` vecinos m√°s cercanos hay m√°s de `r` ejemplos con una clasificaci√≥n distinta a la del propio ejemplo.\n",
    "* Construir un segundo conjunto de datos `Xo_data` obtenido a partir del inicial eliminando todos los ejemplos (5,3)-aislados.\n",
    "* Construir dos modelos de decisi√≥n (para valores de `p` y `k` coherentes con la b√∫squeda de ejemplos aislados), uno para cada conjunto de datos considerado `X_data` y `Xo_data`, realizando en ambos casos una separaci√≥n del $30$% de datos de prueba y $70$% de datos de entrenamiento.\n",
    "* Comparar el rendimiento de ambos modelos sobre su correspondiente conjunto de prueba.\n",
    "\n",
    "El **desarrollo tiene que estar razonado**, indicando en cada apartado qu√© se est√° haciendo, **demostrando as√≠ el conocimiento adquirido en este m√≥dulo**. ¬øQu√© conclusiones puedes sacar de lo aprendido sobre aprendizaje basado en instancias?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apartado 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La clase **NearestNeighbors** posee los m√©todos necesarios para hallar la serie de vecinos de un miembro del conjunto. \n",
    "B√°sicamente crearemos un objeto de este tipo mediante su constructor, que no tiene par√°metros obligatorios, pero con el cual podemos definir:\n",
    "\n",
    "* **n_neighbors**: Por defecto = 5. Es el n√∫mero de vecinos que ser√°n determinantes en la b√∫squeda, el **k** de nuestro algoritmo **knn**.\n",
    "* **radius**: Por defecto = 1.0. Lo usamos si queremos que el radio de distancia respecto al miembro del conjunto sea determinante y no lo sea √∫nicamente el n√∫mero de vecinos sin importar su distancia.\n",
    "* **algorithm**: Para definir qu√© algoritmo queremos utilizar. Por defecto es 'auto', que determina el algoritmo autom√°ticamente en base a los datos de aprendizaje.\n",
    "* **otros**: El contructor de NearestNeighbors puede utilizar otros par√°metros como **metric** o **p**, ya visto anteriormente en el m√≥dulo para seleccionar el m√©todo de medici√≥n de distancias. \n",
    "\n",
    "Para el presente ejercicio s√≥lo usaremos **n_neighbors** para definir nuestra **k**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import NearestNeighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Otro aspecto importante de la clase **NearestNeighbors** ser√°n sus m√©todos **fit()** y **kneighbors()**.\n",
    "\n",
    "* **fit()**: A este m√©todo le pasaremos nuestro conjunto de datos completo y nos servir√° para entrenar el algortimo.\n",
    "* **kneighbors()**: Con este m√©todo podemos encontrar los vecinos del miembro que pasamos como argumento. Pasamos el conjunto de datos, el k deseado y por √∫ltimo especificamos si queremos que se a√±adan las distancias al array resultante.\n",
    "\n",
    "Veamos un ejemplo simple:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2, 0]], dtype=int64)"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "#Nuestro conjunto de datos\n",
    "samples = [[0, 0, 2], [1, 0, 0], [0, 0, 1]]\n",
    "\n",
    "#Definimos el objeto con k=2 y radio=0.4\n",
    "neigh = NearestNeighbors(n_neighbors=2, radius=0.4)\n",
    "#Entrenamos\n",
    "neigh.fit(samples)\n",
    "\n",
    "#¬øCu√°les son los 2 vecinos m√°s cercanos de [0, 0, 1.3] en samples = [[0, 0, 2], [1, 0, 0], [0, 0, 1]]?\n",
    "neigh.kneighbors([[0, 0, 1.3]], 2, return_distance=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como podemos observar, el m√©todo devuelve un conjunto de √≠ndices. Los √≠ndices 2 y 0 nos muestran que [0, 0, 1] y [0, 0, 2] son los 2 vecinos m√°s cercanos a [0, 0, 1.3]."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apartado 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a crear el m√©todo **buscaOutliers**, que encuentra los elementos **(ùëò,ùëü)-aislado** del conjunto de datos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este m√©todo vamos a recorrer **X_data** de principio a fin. Para cada uno de sus elemento comprobaremos de entre sus **k-vecinos** cu√°les son de un tipo diferente al del elemento de la instancia actual. En el ejercicio se ha tenido en cuenta que **kneighbors** devuelve tambi√©n el propio elemento de la instancia puesto que su distancia es 0. Por ello, de manera interna, usaremos k+1 al buscar los vecinos y posteriormente borraremos el primer elemento de la lista, siendo √©ste el propio elemento de la instancia, que es considerado trivial para determinar la informaci√≥n que deseamos encontrar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def buscaOutliers(k,r):\n",
    "    #Defino NearestNeighbors para k+1 vecinos y lo entreno con todo mi conjunto de datos\n",
    "    neigh = NearestNeighbors(n_neighbors=k+1)\n",
    "    neigh.fit(X_data, y_data)\n",
    "    outliers_array = []\n",
    "    for objetivo in range(len(X_data)):\n",
    "        #Encuentro los k+1 vecinos del actual objetivo\n",
    "        vecinos_posible_outlier = neigh.kneighbors([X_data[objetivo]],return_distance=False)\n",
    "        #Elimino el primer elemento del array, es decir, el objetivo en s√≠ mismo\n",
    "        vecinos_posible_outlier2 = np.delete(vecinos_posible_outlier,0)\n",
    "        #Recojo en un array el conjunto de datos de los vecinos\n",
    "        vecinos_data = y_names[y_data[vecinos_posible_outlier2]]\n",
    "        #Compruebo de entre los vecinos, cu√°les son del mismo tipo que el objetivo. \n",
    "        #Si el total es menor que k-r, objetivo es outlier\n",
    "        if(np.count_nonzero(vecinos_data == y_names[y_data[objetivo]]) < (k-r)):\n",
    "            outliers_array.append(objetivo)        \n",
    "    return outliers_array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apartado 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Busquemos los **outliers** de nuestro conjunto de datos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3, 14, 26, 38, 39, 41, 86, 91, 92, 99, 135, 146, 157, 190, 194, 209, 215, 297, 363, 379, 385, 430, 465, 491, 536]\n"
     ]
    }
   ],
   "source": [
    "outliers = buscaOutliers(5,3)\n",
    "print(outliers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "√âste ser√≠a el conjunto de √≠ndices indicando todos los elementos pertenecientes a nuestro datos que son sonsiderados **outliers** para **k=5** y **r=3**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para contruir **Xo_data** basta con eliminar los elementos **outliers** del conjunto **X_data**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xo_data = np.delete(X_data,outliers, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tambi√©n debemos eliminar los elementos de **y_data**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "yo_data = np.delete(y_data,outliers, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con esto queda listo nuestro conjunto de datos **Xo_data**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apartado 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a crear los modelos de decisi√≥n de **x_data** y **Xo_data**. Para ello usaremos la librer√≠a **model_selection**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Empezamos con el conjunto **x_data**, haremos una divisi√≥n 70/30 en los datos de entrenamiento/prueba. Bastar√° con que especifiquemos el valor de **0.30** para test_size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = \\\n",
    "  train_test_split(X_data,y_data,test_size = 0.30,\n",
    "                   random_state=4861,stratify=y_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuaci√≥n usaremos la clase **KNeighborsClassifier** para la construcci√≥n del modelo. √âsto nos permitir√° utilizar los m√©todos necesarios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usamos **k=5** tal y como hicimos al buscar los outliers. Tambi√©n respetaremos el m√©todo de medici√≥n de distancias, distancias euclideas, usado anteriormente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn1 = KNeighborsClassifier(n_neighbors=5,p=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entrenamos el modelo con los datos de training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier()"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn1.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9415204678362573"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn1.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definimos **y_clas** que contendr√° "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, 1, 1, 1, 1, 1, 1, 0])"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_clas = knn1.predict(X_test)\n",
    "y_clas[y_clas != y_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0,\n",
       "       1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1,\n",
       "       0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1,\n",
       "       1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1,\n",
       "       1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
       "       0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1,\n",
       "       0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn1.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0,\n",
       "       1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1,\n",
       "       0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0,\n",
       "       1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1,\n",
       "       1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0,\n",
       "       0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1,\n",
       "       0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(171,)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apartado 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9415204678362573"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn1.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OTHER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dato ( 568 ):  [7.760e+00 2.454e+01 4.792e+01 1.810e+02 5.263e-02 4.362e-02 0.000e+00\n",
      " 0.000e+00 1.587e-01 5.884e-02 3.857e-01 1.428e+00 2.548e+00 1.915e+01\n",
      " 7.189e-03 4.660e-03 0.000e+00 0.000e+00 2.676e-02 2.783e-03 9.456e+00\n",
      " 3.037e+01 5.916e+01 2.686e+02 8.996e-02 6.444e-02 0.000e+00 0.000e+00\n",
      " 2.871e-01 7.039e-02]\n",
      "  Clasificaci√≥n:  benign\n"
     ]
    }
   ],
   "source": [
    "def datoIesimo(i):\n",
    "    print(\"Dato (\",i,\"): \",cancer['data'][i])\n",
    "    print(\"  Clasificaci√≥n: \",cancer['target_names'][cancer['target'][i]])\n",
    "    \n",
    "datoIesimo(568)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "def representacion_grafica(datos,caracteristicas,objetivo,clases,c1,c2):\n",
    "    for tipo,marca,color in zip(range(len(clases)),\"soD\",\"rgb\"):\n",
    "        xs = datos[objetivo == tipo,c1]\n",
    "        ys = datos[objetivo == tipo,c2]\n",
    "        plt.scatter(xs,ys,marker=marca,c=color)\n",
    "    plt.xlabel(caracteristicas[c1])\n",
    "    plt.ylabel(caracteristicas[c2])\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
